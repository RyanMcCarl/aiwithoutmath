# Artificial intelligence without math

Abstract:
If we want nontechnical stakeholders to respond to AI developments in an informed way, we must help them acquire a more-than-superficial understanding of artificial intelligence (AI) and machine learning (ML). Explanations involving advanced math will not reach most people who need to make informed decisions about AI. We believe it is possible to teach many AI and ML concepts without slipping into advanced math or insider jargon.

Introduction:

Artificial intelligence (AI) and machine learning (ML) are transforming industries, societies, and economies, and the pace of change is accelerating. Businesspeople, lawyers, policymakers, and other stakeholders will increasingly face practical questions ("Should my firm adopt this AI-related product?") as well as political and ethical questions ("Should the government be banned from using face-recognition technology?") related to AI.

If we want nontechnical stakeholders to respond to AI developments in an informed way, we must develop ways to help them acquire a reasonable understanding of what AI and ML are and how different techniques work. Many institutions and individuals have been developing teaching materials, but this remains an incompletely solved problem.

Many resources on AI and ML are either too general or too technical. There are many high-level overviews of AI and ML that can give stakeholders a sense of what these concepts refer to. But many stakeholders will need more than just a broad overview. Some will want to peek "under the hood" of AI and ML technologies to get a basic understanding of how they work and why one might use one technique as opposed to another.

General overviews are often insufficient for the purposes of sophisticated decisionmakers such as judges and regulators. Technical explanations, however, often fall into the trap of remaining too general or overestimating the learner's prior knowledge.

Sophisticated but nontechnical stakeholders should be empowered to think about AI and ML at a more-than-superficial level even if they lack the mathematical and technical background of computer scientists. In some cases, curiosity will drive them to "dig deeper"; in other cases, a superficial understanding will be inadequate for a task they face. A judge faced with dispositive motions in a software patent case--or one considering whether to overturn a conviction on the grounds that the police used some algorithm or ML technique in their investigation--will have an ethical duty to try to understand the technology at issue in the case if doing so is necessary to achieve a just and legally correct outcome.

Neither judges nor policymakers will blindly defer to the expertise of computer scientists. AI researchers have therefore highlighted the need for "explainability": AI systems must be able to "explain" why solutions they propose are trustworthy. Different levels of explanation--some more in-depth, some less--are appropriate for different audiences, and some audiences will be more trusting than others.

In-depth explanations risk presuming a shared basic literacy about AI and ML. That may be a mistake. We should not overestimate people's technical or mathematical knowledge. It is likely that fewer than 90% of Americans and Canadians can solve calculus problems, for example. Explanations involving advanced math will therefore not reach many people who need to make informed decisions about AI.

We believe it is possible to teach many AI and ML concepts without slipping into advanced math or insider jargon. As Steven Skiena has written, "[t]he heart of any algorithm is an _idea_."[^1] Advanced math is rarely the only way to communicate such an idea.

We have therefore developed a prototype website to communicate fundamental AI and ML concepts to an educated but nontechnical audience. This website can be found at https://aiwithoutmath.com.[^2] We hope to expand the website to include many more topics as well as nontechnical concepts (such as "explanability") that form part of the shared vocabulary of AI researchers. Other ideas for the website include offering alternative explanations for complicated topics (perhaps with some voting mechanism, similar to that used on StackOverflow and Quora, in which readers can upvote and downvote explanations); linking to off-site explanations; and illustrating concepts with multimedia resources such as videos, games, and demonstrations.

<br>
# Credits
<br>

- Founder and Editor-in-Chief: [Ryan McCarl](http://ryanmccarl.com)
- This website was imagined and prototyped at the 2019 Summer Institute on AI and Society hosted by the [Alberta Machine Intelligence Institute](https://www.amii.ca/) and sponsored by [CIFAR](https://www.cifar.ca/) and the [PULSE Project](http://aipulse.org) at the UCLA School of Law. The following people participated in the workgroup and developed the initial website and its content: Ryan McCarl, Dirk Hovy, Heather von Stackelberg, Jodie Lobana, Dania Humaidan, Gursimran Singh, Kristen Schell, Martha White, and Brandon Leshchinskiy.
- Background photo by Florian Weihmann from Pexels.

[^1]: Steven Skiena, The Algorithm Design Manual (2009).

[^2]: This website is a work in progress; in its current version, it is meant to be only a prototype rather than a finished product. However, we are confident that it fills an urgent need and ought to be developed as soon as possible. If you can contribute in any way (content, design, funding, publicity), please contact [Ryan McCarl](mailto:mccarl@law.ucla.edu).
